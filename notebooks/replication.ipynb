{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    print(\"Running on Google Colab, setting up environment\")\n",
    "    colab = True\n",
    "    !pip install scikit-video\n",
    "\n",
    "    !mkdir -p ./src/data  \n",
    "    !mkdir -p ./src/modules  \n",
    "    !mkdir -p ./data\n",
    "    !mkdir -p ./models\n",
    "\n",
    "    !wget -P ./src/data https://raw.githubusercontent.com/quietscientist/Infant_movement_assessment/master/src/data/build_features.py\n",
    "    !wget -P ./src/data https://raw.githubusercontent.com/quietscientist/Infant_movement_assessment/master/src/data/compute_surprise.py\n",
    "    !wget -P ./src/data https://raw.githubusercontent.com/quietscientist/Infant_movement_assessment/master/src/data/load_pose_data.py\n",
    "    !wget -P ./src/data https://raw.githubusercontent.com/quietscientist/Infant_movement_assessment/master/src/data/merge_data_sets.py\n",
    "    !wget -P ./src/data https://raw.githubusercontent.com/quietscientist/Infant_movement_assessment/master/src/data/preprocess_pose_data.py\n",
    "\n",
    "\n",
    "    !wget -P  ./src/modules https://raw.githubusercontent.com/quietscientist/Infant_movement_assessment/master/src/modules/circstats.py\n",
    "    !wget -P  ./src/modules https://raw.githubusercontent.com/quietscientist/Infant_movement_assessment/master/src/modules/skeleton.py\n",
    "    !wget -P  ./src/modules https://raw.githubusercontent.com/quietscientist/Infant_movement_assessment/master/src/modules/util_data.py\n",
    "    !wget -P  ./src/modules https://raw.githubusercontent.com/quietscientist/Infant_movement_assessment/master/src/modules/util_vis.py\n",
    "\n",
    "    sys.path.insert(0,'./src/data')\n",
    "    sys.path.insert(0,'./src/modules')\n",
    "\n",
    "    data_path = './data'\n",
    "    model_path = './models'\n",
    "    home_path = './'\n",
    "\n",
    "else: \n",
    "    colab = False\n",
    "    sys.path.insert(0,'../src/data')\n",
    "    sys.path.insert(0,'../src/modules')\n",
    "\n",
    "    data_path = '../data'\n",
    "    model_path = '../models'\n",
    "    home_path = '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "\n",
    "import load_pose_data\n",
    "import skvideo.io\n",
    "import itertools\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from scipy.linalg import svd\n",
    "import preprocess_pose_data, build_features, merge_data_sets, compute_surprise\n",
    "import  util_vis\n",
    "from util_vis import plot_skel, gen_one_frame, get_one_frame, normm\n",
    "\n",
    "from skeleton import Skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_env():\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    #if data directory is empty, rerun setup \n",
    "    if not os.path.exists(data_path) or len(os.listdir(data_path)) == 0:\n",
    "\n",
    "        if colab:\n",
    "            !wget https://figshare.com/ndownloader/files/15593963?private_link=10034c230ad9b2b2a6a4 -O ./pose_data.zip\n",
    "            !unzip -o ./pose_data.zip -d ./\n",
    "\n",
    "\n",
    "            !mv --force ./infant_movement_assessment_repo_files/data/* ./data\n",
    "            !mv --force ./infant_movement_assessment_repo_files/models/* ./models\n",
    "\n",
    "            !rm ./pose_data.zip\n",
    "            !rm -r ./infant_movement_assessment_repo_files\n",
    "\n",
    "        else:\n",
    "            !wget https://figshare.com/ndownloader/files/15593963?private_link=10034c230ad9b2b2a6a4 -O ../pose_data.zip\n",
    "            !unzip -o ../pose_data.zip -d ../\n",
    "\n",
    "\n",
    "            !mv --force ../infant_movement_assessment_repo_files/data/* ../data\n",
    "            !mv --force ../infant_movement_assessment_repo_files/models/* ../models\n",
    "\n",
    "            !rm ../pose_data.zip\n",
    "            !rm -r ../infant_movement_assessment_repo_files\n",
    "    else: \n",
    "        print('setup for this project has already been done. Skipping download and extraction of data.')\n",
    "\n",
    "def compute_kinematics(datasets, data_path):\n",
    "    for data_set in data_sets:\n",
    "        print(f'Processing {data_set} data set')\n",
    "\n",
    "        raw_pose_estimates_video_path = f'{data_path}/pose_estimates/{data_set}/py/pose_estimates.pkl'\n",
    "        assert os.path.exists(raw_pose_estimates_video_path), 'Folder does not exist. \\n Edit path to pose estimate data (raw_pose_estimates_video_path) in notebooks/infant_move/master.ipynb, Cell 2.'\n",
    "\n",
    "        #load_pose_data.main(data_set, raw_pose_estimates_video_path)\n",
    "        preprocess_pose_data.main(data_set, data_path)\n",
    "        build_features.main(data_set, data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coco_to_openpose(coco_keypoints):\n",
    "    \"\"\"\n",
    "    Convert COCO keypoints to OpenPose keypoints with the neck keypoint as the midpoint between the two shoulders.\n",
    "    COCO keypoints format (17 keypoints): [nose, left_eye, right_eye, left_ear, right_ear,\n",
    "                                           left_shoulder, right_shoulder, left_elbow, right_elbow,\n",
    "                                           left_wrist, right_wrist, left_hip, right_hip,\n",
    "                                           left_knee, right_knee, left_ankle, right_ankle]\n",
    "    OpenPose keypoints format (18 keypoints): COCO keypoints + [neck]\n",
    "    The neck is not a part of COCO keypoints and is computed as the midpoint between the left and right shoulders.\n",
    "    \"\"\"\n",
    "\n",
    "    # Assuming coco_keypoints is a list of (x, y) tuples\n",
    "    nose, left_eye, right_eye, left_ear, right_ear, \\\n",
    "    left_shoulder, right_shoulder, left_elbow, right_elbow, \\\n",
    "    left_wrist, right_wrist, left_hip, right_hip, \\\n",
    "    left_knee, right_knee, left_ankle, right_ankle = coco_keypoints\n",
    "\n",
    "    # Calculate the neck as the midpoint between left_shoulder and right_shoulder\n",
    "    neck_x = (left_shoulder[0] + right_shoulder[0]) / 2\n",
    "    neck_y = (left_shoulder[1] + right_shoulder[1]) / 2\n",
    "    neck = (neck_x, neck_y)\n",
    "\n",
    "    # Construct the OpenPose keypoints including the neck\n",
    "    openpose_keypoints = [\n",
    "        nose, left_eye, right_eye, left_ear, right_ear,\n",
    "        left_shoulder, right_shoulder, left_elbow, right_elbow,\n",
    "        left_wrist, right_wrist, left_hip, right_hip,\n",
    "        left_knee, right_knee, left_ankle, right_ankle,\n",
    "        neck  # Adding the neck as the last keypoint\n",
    "    ]\n",
    "\n",
    "    return openpose_keypoints\n",
    "\n",
    "def reorder_keypoints(keypoints):\n",
    "    \"\"\"\n",
    "    Reorder the keypoints to the OpenPose format.\n",
    "    The OpenPose format is as follows:\n",
    "    0-17: [nose, neck, right_shoulder, right_elbow, right_wrist, left_shoulder, left_elbow, left_wrist,\n",
    "           right_hip, right_knee, right_ankle, left_hip, left_knee, left_ankle, right_eye, left_eye, right_ear, left_ear]\n",
    "    The input 'keypoints' is a list of (x, y, c) tuples, where c is the confidence score.\n",
    "    \"\"\"\n",
    "\n",
    "    # Reorder the keypoints to the OpenPose format\n",
    "    keypoints = [keypoints[i] for i in [0, 17, 6, 8, 10, 5, 7, 9, 12, 14, 16, 11, 13, 15, 2, 1, 4, 3]]\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "def rescale_keypoints(keypoints, scale):\n",
    "    \"\"\"\n",
    "    Rescale the keypoints by the given scale.\n",
    "    The input 'keypoints' is a list of (x, y) tuples\n",
    "    \"\"\"\n",
    "\n",
    "    # Rescale the keypoints\n",
    "    keypoints = [(x * scale, y * scale) for (x, y) in keypoints]\n",
    "\n",
    "    return keypoints"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
