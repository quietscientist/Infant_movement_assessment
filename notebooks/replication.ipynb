{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    print(\"Running on Google Colab, setting up environment\")\n",
    "    colab = True\n",
    "    !pip install scikit-video\n",
    "\n",
    "    !mkdir -p ./src/data  \n",
    "    !mkdir -p ./src/modules  \n",
    "    !mkdir -p ./data\n",
    "    !mkdir -p ./models\n",
    "\n",
    "    !wget -P ./src/data https://raw.githubusercontent.com/quietscientist/Infant_movement_assessment/master/src/data/build_features.py\n",
    "    !wget -P ./src/data https://raw.githubusercontent.com/quietscientist/Infant_movement_assessment/master/src/data/compute_surprise.py\n",
    "    !wget -P ./src/data https://raw.githubusercontent.com/quietscientist/Infant_movement_assessment/master/src/data/load_pose_data.py\n",
    "    !wget -P ./src/data https://raw.githubusercontent.com/quietscientist/Infant_movement_assessment/master/src/data/merge_data_sets.py\n",
    "    !wget -P ./src/data https://raw.githubusercontent.com/quietscientist/Infant_movement_assessment/master/src/data/preprocess_pose_data.py\n",
    "\n",
    "\n",
    "    !wget -P  ./src/modules https://raw.githubusercontent.com/quietscientist/Infant_movement_assessment/master/src/modules/circstats.py\n",
    "    !wget -P  ./src/modules https://raw.githubusercontent.com/quietscientist/Infant_movement_assessment/master/src/modules/skeleton.py\n",
    "    !wget -P  ./src/modules https://raw.githubusercontent.com/quietscientist/Infant_movement_assessment/master/src/modules/util_data.py\n",
    "    !wget -P  ./src/modules https://raw.githubusercontent.com/quietscientist/Infant_movement_assessment/master/src/modules/util_vis.py\n",
    "\n",
    "    sys.path.insert(0,'./src/data')\n",
    "    sys.path.insert(0,'./src/modules')\n",
    "\n",
    "    data_path = './data'\n",
    "    model_path = './models'\n",
    "    home_path = './'\n",
    "\n",
    "else: \n",
    "    colab = False\n",
    "    sys.path.insert(0,'../src/data')\n",
    "    sys.path.insert(0,'../src/modules')\n",
    "\n",
    "    data_path = '../data'\n",
    "    model_path = '../models'\n",
    "    home_path = '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import pickle as pkl\n",
    "\n",
    "\n",
    "import load_pose_data\n",
    "import skvideo.io\n",
    "import itertools\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from scipy.linalg import svd\n",
    "import preprocess_pose_data, build_features, merge_data_sets, compute_surprise\n",
    "import  util_vis\n",
    "from util_vis import plot_skel, gen_one_frame, get_one_frame, normm\n",
    "\n",
    "from skeleton import Skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_env():\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    #if data directory is empty, rerun setup \n",
    "    if not os.path.exists(data_path) or len(os.listdir(data_path)) == 0:\n",
    "\n",
    "        if colab:\n",
    "            !wget https://figshare.com/ndownloader/files/15593963?private_link=10034c230ad9b2b2a6a4 -O ./pose_data.zip\n",
    "            !unzip -o ./pose_data.zip -d ./\n",
    "\n",
    "\n",
    "            !mv --force ./infant_movement_assessment_repo_files/data/* ./data\n",
    "            !mv --force ./infant_movement_assessment_repo_files/models/* ./models\n",
    "\n",
    "            !rm ./pose_data.zip\n",
    "            !rm -r ./infant_movement_assessment_repo_files\n",
    "\n",
    "        else:\n",
    "            !wget https://figshare.com/ndownloader/files/15593963?private_link=10034c230ad9b2b2a6a4 -O ../pose_data.zip\n",
    "            !unzip -o ../pose_data.zip -d ../\n",
    "\n",
    "\n",
    "            !mv --force ../infant_movement_assessment_repo_files/data/* ../data\n",
    "            !mv --force ../infant_movement_assessment_repo_files/models/* ../models\n",
    "\n",
    "            !rm ../pose_data.zip\n",
    "            !rm -r ../infant_movement_assessment_repo_files\n",
    "    else: \n",
    "        print('setup for this project has already been done. Skipping download and extraction of data.')\n",
    "\n",
    "def compute_kinematics(datasets, data_path):\n",
    "    for data_set in data_sets:\n",
    "        print(f'Processing {data_set} data set')\n",
    "\n",
    "        raw_pose_estimates_video_path = f'{data_path}/pose_estimates/{data_set}/py/pose_estimates.pkl'\n",
    "        assert os.path.exists(raw_pose_estimates_video_path), 'Folder does not exist. \\n Edit path to pose estimate data (raw_pose_estimates_video_path) in notebooks/infant_move/master.ipynb, Cell 2.'\n",
    "\n",
    "        #load_pose_data.main(data_set, raw_pose_estimates_video_path)\n",
    "        preprocess_pose_data.main(data_set, data_path)\n",
    "        build_features.main(data_set, data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_keypoints(keypoints):\n",
    "    \"\"\"\n",
    "    Reorder the keypoints to the OpenPose format.\n",
    "    The OpenPose format is as follows:\n",
    "    0-17: [nose, neck, right_shoulder, right_elbow, right_wrist, left_shoulder, left_elbow, left_wrist,\n",
    "           right_hip, right_knee, right_ankle, left_hip, left_knee, left_ankle, right_eye, left_eye, right_ear, left_ear]\n",
    "    The input 'keypoints' is a list of (x, y, c) tuples, where c is the confidence score.\n",
    "    \"\"\"\n",
    "\n",
    "    # Reorder the keypoints to the OpenPose format\n",
    "    keypoints = [keypoints[i] for i in [0, 17, 6, 8, 10, 5, 7, 9, 12, 14, 16, 11, 13, 15, 2, 1, 4, 3]]\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "def rescale_keypoints(keypoints, scale):\n",
    "    \"\"\"\n",
    "    Rescale the keypoints by the given scale.\n",
    "    The input 'keypoints' is a list of (x, y) tuples\n",
    "    \"\"\"\n",
    "\n",
    "    # Rescale the keypoints\n",
    "    keypoints = [(x * scale, y * scale) for (x, y) in keypoints]\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "\n",
    "def convert_coco_to_openpose(coco_keypoints):\n",
    "    \"\"\"\n",
    "    Convert COCO keypoints to OpenPose keypoints with the neck keypoint as the midpoint between the two shoulders.\n",
    "    COCO keypoints format (17 keypoints): [nose, left_eye, right_eye, left_ear, right_ear,\n",
    "                                           left_shoulder, right_shoulder, left_elbow, right_elbow,\n",
    "                                           left_wrist, right_wrist, left_hip, right_hip,\n",
    "                                           left_knee, right_knee, left_ankle, right_ankle]\n",
    "    OpenPose keypoints format (18 keypoints): COCO keypoints + [neck]\n",
    "    The neck is not a part of COCO keypoints and is computed as the midpoint between the left and right shoulders.\n",
    "    \"\"\"\n",
    "\n",
    "    # Assuming coco_keypoints is a list of (x, y) tuples\n",
    "    nose, left_eye, right_eye, left_ear, right_ear, \\\n",
    "    left_shoulder, right_shoulder, left_elbow, right_elbow, \\\n",
    "    left_wrist, right_wrist, left_hip, right_hip, \\\n",
    "    left_knee, right_knee, left_ankle, right_ankle = coco_keypoints\n",
    "\n",
    "    # Calculate the neck as the midpoint between left_shoulder and right_shoulder\n",
    "    neck_x = (left_shoulder[0] + right_shoulder[0]) / 2\n",
    "    neck_y = (left_shoulder[1] + right_shoulder[1]) / 2\n",
    "    neck = (neck_x, neck_y)\n",
    "\n",
    "    # Construct the OpenPose keypoints including the neck\n",
    "    openpose_keypoints = [\n",
    "        nose, left_eye, right_eye, left_ear, right_ear,\n",
    "        left_shoulder, right_shoulder, left_elbow, right_elbow,\n",
    "        left_wrist, right_wrist, left_hip, right_hip,\n",
    "        left_knee, right_knee, left_ankle, right_ankle,\n",
    "        neck  # Adding the neck as the last keypoint\n",
    "    ]\n",
    "\n",
    "    openpose_keypoints = reorder_keypoints(openpose_keypoints)\n",
    "    openpose_keypoints = rescale_keypoints(openpose_keypoints, 1)\n",
    "\n",
    "    return openpose_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Load the new coco-formatted pose estimates (1 json file per video)\n",
    "json_path = '../data/coco_pose_estimates/YT'\n",
    "json_files = os.listdir(json_path)\n",
    "\n",
    "save_path = '../data/pose_estimates/youtube_2024/py/'\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "kp_mapping = {0:'Nose', 1:'Neck', 2:'RShoulder', 3:'RElbow', 4:'RWrist', 5:'LShoulder', 6:'LElbow', \n",
    "              7:'LWrist', 8:'RHip', 9:'RKnee', 10:'RAnkle', 11:'LHip', \n",
    "              12:'LKnee', 13:'LAnkle', 14:'REye', 15:'LEye', 16:'REar', 17:'LEar'}\n",
    "\n",
    "# Define the DataFrame columns as specified\n",
    "columns = ['video_number', 'video', 'bp', 'frame', 'x', 'y', 'fps', 'pixel_x', 'pixel_y', 'time', 'part_idx']\n",
    "data = []  # This will hold the data to be loaded into the DataFrame\n",
    "#vid_info = pd.read_csv('../data/vid_info.csv')\n",
    "\n",
    "for file_number, file in enumerate(json_files, start=0):\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(json_path, file)\n",
    "    fname = file.split('.')[0]\n",
    "\n",
    "    fps = 30#vid_info[vid_info['video'] == fname]['fps'].values[0]\n",
    "    pixel_x = 1280#vid_info[vid_info['video'] == fname]['pixel_x'].values[0]\n",
    "    pixel_y = 600#vid_info[vid_info['video'] == fname]['pixel_y'].values[0]\n",
    "\n",
    "    # Open and load the JSON data\n",
    "    with open(file_path, 'r') as f:\n",
    "        frames = json.load(f)\n",
    "        \n",
    "        # Iterate through each frame in the JSON file\n",
    "        for frame in frames:\n",
    "            frame_id = frame['frame_id']\n",
    "            if 'instances' in frame and len(frame['instances']) > 0:\n",
    "                keypoints = frame['instances'][0]['keypoints']\n",
    "                keypoints = convert_coco_to_openpose(keypoints)\n",
    "\n",
    "                # Iterate through each keypoint\n",
    "                for part_idx, (x, y) in enumerate(keypoints):\n",
    "                    # Assuming you have a way to map part_idx to a body part name 'bp'\n",
    "\n",
    "                    bp = kp_mapping[part_idx]  # Placeholder, replace with actual mapping if available\n",
    "                    fps = 30  # Placeholder, adjust as necessary based on your data or metadata\n",
    "                    time = frame_id / fps\n",
    "                    \n",
    "                    # Append data for this body part\n",
    "                    row = [file_number, fname, bp, frame_id, x, y, fps, pixel_x, pixel_y, time, part_idx]\n",
    "                    data.append(row)\n",
    "\n",
    "# Create DataFrame from the accumulated data\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_pickle(save_path + 'pose_estimates.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = ['youtube', 'clinical', 'youtube_2024']\n",
    "age_threshold = 10\n",
    "\n",
    "processed_data_path = f'{data_path}/processed/'\n",
    "updated_data_path = f'{data_path}/updated/'\n",
    "\n",
    "feature_path = f'{data_path}/interim'\n",
    "meta_data_path = f'{data_path}/video_meta_data'\n",
    "save_path = f'{data_path}/processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_env()\n",
    "compute_kinematics(data_sets, data_path)\n",
    "merge_data_sets.main(feature_path, meta_data_path, save_path, age_threshold)\n",
    "compute_surprise.main(processed_data_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
